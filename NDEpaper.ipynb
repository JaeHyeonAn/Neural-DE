{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code is about simple OU process with 4 methods,\n",
        "\n",
        "Neural SDE, Neural LSDE, Neural LNSDE and Neural GSDE, given by authors of the paper.\n",
        "\n",
        "You can compare each training losses at below and this is essentially doing same with the Figure.2 in the paper."
      ],
      "metadata": {
        "id": "ZChkbltNDs9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchcde\n",
        "import torchsde\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Setup seed for reproducibility\n",
        "def seed_everything(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "8euxsVpo0khw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ou_process(T, N, theta, mu, sigma, X0):\n",
        "    \"\"\"\n",
        "    Simulate the Ornstein-Uhlenbeck process.\n",
        "\n",
        "    Parameters:\n",
        "    T (float): Total time.\n",
        "    N (int): Number of time steps.\n",
        "    theta (float): Rate of mean reversion.\n",
        "    mu (float): Long-term mean.\n",
        "    sigma (float): Volatility.\n",
        "    X0 (float): Initial value.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: Simulated values of the OU process.\n",
        "    \"\"\"\n",
        "    dt = T / N\n",
        "    t = np.linspace(0, T, N)\n",
        "    X = np.zeros(N)\n",
        "    X[0] = X0\n",
        "\n",
        "    for i in range(1, N):\n",
        "        dW = np.random.normal(0, np.sqrt(dt))\n",
        "        X[i] = X[i-1] + theta * (mu - X[i-1]) * dt + sigma * dW\n",
        "\n",
        "    return t, X\n",
        "\n",
        "def generate_data(num_samples, T, N, theta, mu, sigma, X0):\n",
        "    data_list = []\n",
        "    for _ in range(num_samples):\n",
        "        t, X = ou_process(T, N, theta, mu, sigma, X0)\n",
        "        data_list.append([t, X])\n",
        "\n",
        "    total_data = torch.Tensor(np.array(data_list))  # [Batch size, Dimension, Length]\n",
        "    total_data = total_data.permute(0, 2, 1)  # [Batch size, Length, Dimension]\n",
        "\n",
        "    max_len = total_data.shape[1]\n",
        "    times = torch.linspace(0, 1, max_len)\n",
        "    coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(total_data, times)\n",
        "\n",
        "    return total_data, coeffs, times\n",
        "\n",
        "class OU_Dataset(Dataset):\n",
        "    def __init__(self, data, coeffs):\n",
        "        self.data = data\n",
        "        self.coeffs = coeffs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.data[idx, ...],\n",
        "            self.coeffs[idx, ...],\n",
        "        )\n",
        "\n",
        "def split_data(data, coeffs, train_ratio=0.8):\n",
        "    total_size = len(data)\n",
        "    train_size = int(total_size * train_ratio)\n",
        "\n",
        "    train_idx = np.random.choice(range(total_size), train_size, replace=False)\n",
        "    test_idx = np.array([i for i in range(total_size) if i not in train_idx])\n",
        "\n",
        "    train_data = data[train_idx, ...]\n",
        "    test_data = data[test_idx, ...]\n",
        "    train_coeffs = coeffs[train_idx, ...]\n",
        "    test_coeffs = coeffs[test_idx, ...]\n",
        "\n",
        "    return train_data, train_coeffs, test_data, test_coeffs\n",
        "\n",
        "def create_data_loaders(train_data, train_coeffs, test_data, test_coeffs, batch_size=16):\n",
        "    train_dataset = OU_Dataset(train_data, train_coeffs)\n",
        "    test_dataset = OU_Dataset(test_data, test_coeffs)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Parameters\n",
        "config = {\n",
        "    'num_samples': 1000,\n",
        "    'T': 10.0,\n",
        "    'N': 20,\n",
        "    'theta': 0.2,\n",
        "    'mu': 0.0,\n",
        "    'sigma': 0.1,\n",
        "    'X0': 1.0,\n",
        "    'train_ratio': 0.8,\n",
        "    'batch_size': 16,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "# Ensure reproducibility\n",
        "seed_everything(config['seed'])\n",
        "\n",
        "# Generate data\n",
        "total_data, coeffs, times = generate_data(config['num_samples'], config['T'], config['N'], config['theta'], config['mu'], config['sigma'], config['X0'])\n",
        "\n",
        "# Split data\n",
        "train_data, train_coeffs, test_data, test_coeffs = split_data(total_data, coeffs, config['train_ratio'])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, test_loader = create_data_loaders(train_data, train_coeffs, test_data, test_coeffs, config['batch_size'])\n"
      ],
      "metadata": {
        "id": "mJk6AQTM0n-5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LipSwish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.909 * torch.nn.functional.silu(x)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_size, out_size, hidden_dim, num_layers, tanh=False, activation='lipswish'):\n",
        "        super().__init__()\n",
        "\n",
        "        if activation == 'lipswish':\n",
        "            activation_fn = LipSwish()\n",
        "        else:\n",
        "            activation_fn = nn.ReLU()\n",
        "\n",
        "        model = [nn.Linear(in_size, hidden_dim), activation_fn]\n",
        "        for _ in range(num_layers - 1):\n",
        "            model.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            model.append(activation_fn)\n",
        "        model.append(nn.Linear(hidden_dim, out_size))\n",
        "        if tanh:\n",
        "            model.append(nn.Tanh())\n",
        "        self._model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._model(x)"
      ],
      "metadata": {
        "id": "VwACBxyNBG12"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralSDEFunc(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, hidden_hidden_dim, num_layers, activation='lipswish'):\n",
        "        super(NeuralSDEFunc, self).__init__()\n",
        "        self.sde_type = \"ito\"\n",
        "        self.noise_type = \"diagonal\" # or \"scalar\"\n",
        "\n",
        "        self.linear_in = nn.Linear(hidden_dim + 1, hidden_dim)\n",
        "        self.f_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "        self.linear_out = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.noise_in = nn.Linear(hidden_dim + 1, hidden_dim)\n",
        "        self.g_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "\n",
        "    def set_X(self, coeffs, times):\n",
        "        self.coeffs = coeffs\n",
        "        self.times = times\n",
        "        self.X = torchcde.CubicSpline(self.coeffs, self.times)\n",
        "\n",
        "    def f(self, t, y):\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # yy = self.linear_in(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
        "        yy = self.linear_in(torch.cat((t, y), dim=-1))\n",
        "        return self.f_net(yy)\n",
        "\n",
        "    def g(self, t, y):\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # yy = self.noise_in(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
        "        yy = self.noise_in(torch.cat((t, y), dim=-1))\n",
        "        return self.g_net(yy)\n",
        "\n",
        "class NeuralLSDEFunc(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, hidden_hidden_dim, num_layers, activation='lipswish'):\n",
        "        super(NeuralLSDEFunc, self).__init__()\n",
        "        self.sde_type = \"ito\"\n",
        "        self.noise_type = \"diagonal\" # or \"scalar\"\n",
        "\n",
        "        # self.linear_in = nn.Linear(hidden_dim + 1, hidden_dim)\n",
        "        self.linear_X = nn.Linear(input_dim, hidden_dim)\n",
        "        self.emb = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        self.f_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "        self.linear_out = nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.noise_in = nn.Linear(1, hidden_dim)\n",
        "        self.g_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "\n",
        "    def set_X(self, coeffs, times):\n",
        "        self.coeffs = coeffs\n",
        "        self.times = times\n",
        "        self.X = torchcde.CubicSpline(self.coeffs, self.times)\n",
        "\n",
        "    def f(self, t, y):\n",
        "        Xt = self.X.evaluate(t)\n",
        "        Xt = self.linear_X(Xt)\n",
        "\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # yy = self.linear_in(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
        "        # yy = self.linear_in(torch.cat((t, y), dim=-1))\n",
        "        z = self.emb(torch.cat([y,Xt], dim=-1))\n",
        "        z = self.f_net(z)\n",
        "        return self.linear_out(z)\n",
        "\n",
        "    def g(self, t, y):\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # tt = self.noise_in(torch.cat((torch.sin(t), torch.cos(t)), dim=-1))\n",
        "        tt = self.noise_in(t)\n",
        "        return self.g_net(tt)\n",
        "\n",
        "class NeuralLNSDEFunc(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, hidden_hidden_dim, num_layers, activation='lipswish'):\n",
        "        super(NeuralLNSDEFunc, self).__init__()\n",
        "        self.sde_type = \"ito\"\n",
        "        self.noise_type = \"diagonal\" # or \"scalar\"\n",
        "\n",
        "        self.linear_in = nn.Linear(hidden_dim + 1, hidden_dim)\n",
        "        self.linear_X = nn.Linear(input_dim, hidden_dim)\n",
        "        self.emb = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        self.f_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "        self.linear_out = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.noise_in = nn.Linear(1, hidden_dim)\n",
        "        self.g_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "\n",
        "    def set_X(self, coeffs, times):\n",
        "        self.coeffs = coeffs\n",
        "        self.times = times\n",
        "        self.X = torchcde.CubicSpline(self.coeffs, self.times)\n",
        "\n",
        "    def f(self, t, y):\n",
        "        Xt = self.X.evaluate(t)\n",
        "        Xt = self.linear_X(Xt)\n",
        "\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # yy = self.linear_in(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
        "        yy = self.linear_in(torch.cat((t, y), dim=-1))\n",
        "        z = self.emb(torch.cat([yy,Xt], dim=-1))\n",
        "        z = self.f_net(z)\n",
        "        return self.linear_out(z)\n",
        "\n",
        "    def g(self, t, y):\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # tt = self.noise_in(torch.cat((torch.sin(t), torch.cos(t)), dim=-1))\n",
        "        tt = self.noise_in(t)\n",
        "        return self.g_net(tt)\n",
        "\n",
        "class NeuralGSDEFunc(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, hidden_hidden_dim, num_layers, activation='lipswish'):\n",
        "        super(NeuralGSDEFunc, self).__init__()\n",
        "        self.sde_type = \"ito\"\n",
        "        self.noise_type = \"diagonal\" # or \"scalar\"\n",
        "\n",
        "        self.linear_in = nn.Linear(hidden_dim + 1, hidden_dim)\n",
        "        self.linear_X = nn.Linear(input_dim, hidden_dim)\n",
        "        self.emb = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        self.f_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "        self.linear_out = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.noise_in = nn.Linear(1, hidden_dim)\n",
        "        self.g_net = MLP(hidden_dim, hidden_dim, hidden_hidden_dim, num_layers, activation=activation)\n",
        "\n",
        "    def set_X(self, coeffs, times):\n",
        "        self.coeffs = coeffs\n",
        "        self.times = times\n",
        "        self.X = torchcde.CubicSpline(self.coeffs, self.times)\n",
        "\n",
        "    def f(self, t, y):\n",
        "        Xt = self.X.evaluate(t)\n",
        "        Xt = self.linear_X(Xt)\n",
        "\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # yy = self.linear_in(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
        "        yy = self.linear_in(torch.cat((t, y), dim=-1))\n",
        "        z = self.emb(torch.cat([yy,Xt], dim=-1))\n",
        "        z = self.f_net(z) * y # (1 - torch.nan_to_num(y).sigmoid())\n",
        "        return self.linear_out(z)\n",
        "\n",
        "    def g(self, t, y):\n",
        "        if t.dim() == 0:\n",
        "            t = torch.full_like(y[:, 0], fill_value=t).unsqueeze(-1)\n",
        "        # tt = self.noise_in(torch.cat((torch.sin(t), torch.cos(t)), dim=-1))\n",
        "        tt = self.noise_in(t)\n",
        "        return self.g_net(tt) * y\n",
        "\n",
        "class NDE_model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, activation='lipswish', vector_field=None):\n",
        "        super(NDE_model, self).__init__()\n",
        "        self.func = vector_field(input_dim, hidden_dim, hidden_dim, num_layers, activation=activation)\n",
        "        self.initial = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, coeffs, times):\n",
        "        # control module\n",
        "        self.func.set_X(coeffs, times)\n",
        "\n",
        "        y0 = self.func.X.evaluate(times[0])\n",
        "        y0 = self.initial(y0)\n",
        "\n",
        "        z = torchsde.sdeint(sde=self.func,\n",
        "                            y0=y0,\n",
        "                            ts=times,\n",
        "                            dt=0.05,\n",
        "                            method='euler')\n",
        "        z = z.permute(1,0,2)\n",
        "        return self.decoder(z)"
      ],
      "metadata": {
        "id": "UutaZveEAdzg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "hidden_dim = 32\n",
        "num_layers = 1\n",
        "\n",
        "num_epochs = 100\n",
        "lr = 1e-3"
      ],
      "metadata": {
        "id": "H1Qjg9YJA6IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NDE_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, vector_field=NeuralSDEFunc).to(device)\n",
        "lossSDE = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        coeffs = batch[1].to(device)\n",
        "        times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        true = batch[0][:,:,1].to(device)\n",
        "        pred = model(coeffs, times).squeeze(-1)\n",
        "        loss = criterion(pred, true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    lossSDE.append(total_loss)\n",
        "    if epoch % num_epochs == 0:\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch}, Loss: {avg_loss}')\n",
        "\n",
        "        ##\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_trues = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                coeffs = batch[1].to(device)\n",
        "                times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "                true = batch[0][:,:,1].to(device)\n",
        "                pred = model(coeffs, times).squeeze(-1)\n",
        "                loss = criterion(pred, true)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                all_preds.append(pred.cpu())\n",
        "                all_trues.append(true.cpu())\n",
        "\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "        print(f'Test Loss: {avg_loss}')\n",
        "\n",
        "        all_preds = torch.cat(all_preds, dim=0)\n",
        "        all_trues = torch.cat(all_trues, dim=0)\n",
        "\n",
        "        ##\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(range(1, num_epochs + 1),lossSDE, label=f'SDE Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss over Epochs')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "FRdsTa213rGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NDE_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, vector_field=NeuralLSDEFunc).to(device)\n",
        "lossLSDE = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        coeffs = batch[1].to(device)\n",
        "        times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        true = batch[0][:,:,1].to(device)\n",
        "        pred = model(coeffs, times).squeeze(-1)\n",
        "        loss = criterion(pred, true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    lossLSDE.append(total_loss)\n",
        "    if epoch % num_epochs == 0:\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch}, Loss: {avg_loss}')\n",
        "\n",
        "        ##\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_trues = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                coeffs = batch[1].to(device)\n",
        "                times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "                true = batch[0][:,:,1].to(device)\n",
        "                pred = model(coeffs, times).squeeze(-1)\n",
        "                loss = criterion(pred, true)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                all_preds.append(pred.cpu())\n",
        "                all_trues.append(true.cpu())\n",
        "\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "        print(f'Test Loss: {avg_loss}')\n",
        "\n",
        "        all_preds = torch.cat(all_preds, dim=0)\n",
        "        all_trues = torch.cat(all_trues, dim=0)\n",
        "\n",
        "        ##\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(range(1, num_epochs + 1),lossLSDE, label=f'LSDE Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss over Epochs')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "FPZkPbJ8AbtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NDE_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, vector_field=NeuralLNSDEFunc).to(device)\n",
        "lossLNSDE = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        coeffs = batch[1].to(device)\n",
        "        times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        true = batch[0][:,:,1].to(device)\n",
        "        pred = model(coeffs, times).squeeze(-1)\n",
        "        loss = criterion(pred, true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    lossLNSDE.append(total_loss)\n",
        "    if epoch % num_epochs == 0:\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch}, Loss: {avg_loss}')\n",
        "\n",
        "        ##\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_trues = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                coeffs = batch[1].to(device)\n",
        "                times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "                true = batch[0][:,:,1].to(device)\n",
        "                pred = model(coeffs, times).squeeze(-1)\n",
        "                loss = criterion(pred, true)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                all_preds.append(pred.cpu())\n",
        "                all_trues.append(true.cpu())\n",
        "\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "        print(f'Test Loss: {avg_loss}')\n",
        "\n",
        "        all_preds = torch.cat(all_preds, dim=0)\n",
        "        all_trues = torch.cat(all_trues, dim=0)\n",
        "\n",
        "        ##\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(range(1, num_epochs + 1),lossLNSDE, label=f'LNSDE Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss over Epochs')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "oH2CKax2A176"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NDE_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, vector_field=NeuralGSDEFunc).to(device)\n",
        "lossGSDE = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        coeffs = batch[1].to(device)\n",
        "        times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        true = batch[0][:,:,1].to(device)\n",
        "        pred = model(coeffs, times).squeeze(-1)\n",
        "        loss = criterion(pred, true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    lossGSDE.append(total_loss)\n",
        "    if epoch % num_epochs == 0:\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch}, Loss: {avg_loss}')\n",
        "\n",
        "        ##\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_trues = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                coeffs = batch[1].to(device)\n",
        "                times = torch.linspace(0, 1, batch[0].shape[1]).to(device)\n",
        "\n",
        "                true = batch[0][:,:,1].to(device)\n",
        "                pred = model(coeffs, times).squeeze(-1)\n",
        "                loss = criterion(pred, true)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                all_preds.append(pred.cpu())\n",
        "                all_trues.append(true.cpu())\n",
        "\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "        print(f'Test Loss: {avg_loss}')\n",
        "\n",
        "        all_preds = torch.cat(all_preds, dim=0)\n",
        "        all_trues = torch.cat(all_trues, dim=0)\n",
        "\n",
        "        ##\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(range(1, num_epochs + 1),lossGSDE, label=f'GSDE Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss over Epochs')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "LTSyAVIfC34H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
